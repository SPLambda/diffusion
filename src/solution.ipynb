{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:09:41.482693100Z",
     "start_time": "2023-10-18T14:09:41.455234400Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data aquisition&preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f32636119e6eecfc"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Oxford-IIIT pet dataset: https://www.tensorflow.org/datasets/catalog/oxford_iiit_pet\n",
    "dataset_name = \"oxford_iiit_pet\" # dataset name\n",
    "split = [\n",
    "    \"train[:60%]+test[:60%]\",\n",
    "    \"train[60%:80%]+test[60%:80%]\",\n",
    "    \"train[80%:]+test[80%:]\"\n",
    "] # train-validation-test split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:09:45.544662500Z",
     "start_time": "2023-10-18T14:09:45.530587500Z"
    }
   },
   "id": "2fc6209616453146"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Oxford Flowers 102 dataset: https://www.tensorflow.org/datasets/catalog/oxford_flowers102\n",
    "dataset_name = \"oxford_flowers102\" # dataset name\n",
    "split = [\n",
    "    \"train[:60%]+validation[:60%]+test[:60%]\",\n",
    "    \"train[60%:80%]+validation[60%:80%]+test[60%:80%]\",\n",
    "    \"train[80%:]+validation[80%:]+test[80%:]\"\n",
    "] # train-validation-test split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:09:47.248651600Z",
     "start_time": "2023-10-18T14:09:47.227062900Z"
    }
   },
   "id": "a1638cc90c25dff6"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "img_size = 64 # resized image size\n",
    "batch_size = 64 # batch size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:09:49.348717700Z",
     "start_time": "2023-10-18T14:09:49.329260Z"
    }
   },
   "id": "1f07404a11018525"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def preprocess_image(data): # preprocess an image\n",
    "    height = tf.shape(data[\"image\"])[0]\n",
    "    width = tf.shape(data[\"image\"])[1]\n",
    "    crop_size = tf.minimum(height, width) # find the smallest dimension\n",
    "    img = tf.image.crop_to_bounding_box(\n",
    "        data[\"image\"],\n",
    "        (height - crop_size) // 2,\n",
    "        (width - crop_size) // 2,\n",
    "        crop_size,\n",
    "        crop_size,\n",
    "    ) # crop the image to a square\n",
    "    img = tf.cast(img, dtype=tf.float32) # cast the image to float32\n",
    "    img = tf.image.resize(img, size=(img_size, img_size), antialias=True) # resize the image to img_size x img_size\n",
    "    return tf.clip_by_value(img / 255.0, 0.0, 1.0) # normalize the image to [0, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:09:50.462246200Z",
     "start_time": "2023-10-18T14:09:50.437166500Z"
    }
   },
   "id": "532148c5eab970f6"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset): # preprocess a dataset\n",
    "    return (dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE) # preprocess images of the dataset\n",
    "            .batch(batch_size, drop_remainder=True) # organize the dataset into batches\n",
    "            .shuffle(2 * batch_size) # shuffle the dataset\n",
    "            .prefetch(buffer_size=tf.data.AUTOTUNE)) # prefetch data for better performance\n",
    "\n",
    "def load_data(dataset_name): # load dataset from tensorflow datasets with the given name\n",
    "    train_ds, val_ds, test_ds = tfds.load(dataset_name, split=split, shuffle_files=True) # load the dataset\n",
    "    train_ds = preprocess_dataset(train_ds) # preprocess the training dataset\n",
    "    val_ds = preprocess_dataset(val_ds) # preprocess the validation dataset\n",
    "    test_ds = preprocess_dataset(test_ds) # preprocess the test dataset\n",
    "    return train_ds, val_ds, test_ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:09:52.115428900Z",
     "start_time": "2023-10-18T14:09:52.096184500Z"
    }
   },
   "id": "382d70fa0e9482f7"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = load_data(dataset_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:09:53.886740400Z",
     "start_time": "2023-10-18T14:09:53.064641200Z"
    }
   },
   "id": "442f7de3e655fe7f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
